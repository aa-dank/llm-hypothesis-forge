{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae9b886",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is designed to demonstrate the process of working with economics research papers. It includes steps to fetch a single paper, assess its relevance, generate a false abstract, and compute perplexity scores. The goal is to provide a comprehensive understanding of the workflow and its applications in research data analysis.\n",
    "\n",
    "### Objectives\n",
    "- **Scrape a single economics research paper** from a specified source.\n",
    "- **Assess the paper** for inclusion in the database.\n",
    "- If accepted, **generate a false abstract** for the paper.\n",
    "- **Calculate perplexity scores** for both the original and false abstracts.\n",
    "\n",
    "### Workflow Overview\n",
    "1. **Scraping**: Retrieve a single economics research paper using the DOI.\n",
    "2. **Assessment**: Use the inclusion assessment logic to determine if the paper should be included in the database.\n",
    "3. **False Abstract Generation**: If the paper is accepted, generate a false abstract using a predefined prompt.\n",
    "4. **Perplexity Scoring**: Calculate perplexity scores for both the original and false abstracts to evaluate their linguistic complexity.\n",
    "\n",
    "### Prerequisites\n",
    "- Ensure the database is set up and accessible.\n",
    "- Verify that the necessary Python modules and dependencies are installed.\n",
    "- Confirm access to the required APIs (e.g., OpenAI, arXiv, etc.).\n",
    "\n",
    "\n",
    "Note: This notebook is designed to be run in the project root directory. (Not the containing `notebooks` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e569ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from data.db import get_db_session, close_db_session\n",
    "from data.models import ResearchPaper\n",
    "from data.ingest import download_preprints_with_publication_info\n",
    "from data.generate import assess_papers_by_category, assess_paper_for_inclusion, AbstractModifier\n",
    "from services.llm_services import BasicOpenAI, TogetherClient\n",
    "from services.arxiv import arxiv_taxonomy\n",
    "from prompts_library.data_creation import economics_abstract_modification_prompt\n",
    "from data.utils import zlib_compression_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a977d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def econ_papers_inclusion_assessment(n=10):\n",
    "    \"\"\"\n",
    "    Assesses unreviewed economics papers from the database for inclusion.\n",
    "\n",
    "    Args:\n",
    "        n: Number of papers to assess\n",
    "    \"\"\"\n",
    "    # Get economics categories from arxiv taxonomy\n",
    "    # Ensure arxiv_taxonomy is loaded/available here\n",
    "    # You might need to import it or load it if it's not globally available\n",
    "    try:\n",
    "        from services.arxiv import arxiv_taxonomy # Assuming arxiv_taxonomy is here\n",
    "        economics_categories = list(arxiv_taxonomy.get(\"Economics\", {}).keys())\n",
    "        if not economics_categories:\n",
    "             logging.warning(\"No economics categories found in arxiv_taxonomy.\")\n",
    "             # Decide how to handle this: return, use defaults, or raise error\n",
    "             return\n",
    "    except ImportError:\n",
    "        logging.error(\"Could not import arxiv_taxonomy from services.arxiv.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading economics categories: {e}\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Using categories for economics assessment: {economics_categories}\")\n",
    "\n",
    "    # Call the generic assessment function\n",
    "    assess_papers_by_category(\n",
    "        domain=\"economics\",\n",
    "        categories=economics_categories,\n",
    "        limit=n\n",
    "        # llm_client can be omitted to let the generic function create one\n",
    "    )\n",
    "\n",
    "def download_economics_papers(start_date, end_date, n_samples, output_format='json', published_in_journal=None):\n",
    "    \"\"\"\n",
    "    Downloads ResearchPaper objects for the domain of economics using arXiv taxonomy.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): Start date in YYYY-MM-DD format.\n",
    "        end_date (str): End date in YYYY-MM-DD format.\n",
    "        n_samples (int): Total number of papers to download.\n",
    "        output_format (str): Output format (default is 'json').\n",
    "        published_in_journal (str): Optional - Filter for papers published in a specific journal.\n",
    "    \"\"\"\n",
    "    # Get economics-related categories from arXiv taxonomy\n",
    "    economics_categories = [\n",
    "        f\"cat:{code}\" for code in arxiv_taxonomy.get(\"Economics\", {}).keys()\n",
    "    ]\n",
    "    if not economics_categories:\n",
    "        logging.info(\"No economics categories found in arXiv taxonomy.\")\n",
    "        return\n",
    "\n",
    "    # Join the categories with OR for the search query\n",
    "    economics_category_query = \" OR \".join(economics_categories)\n",
    "    logging.info(f\"Using arXiv categories for economics: {economics_category_query}\")\n",
    "\n",
    "    # Calculate the number of pagination cursors\n",
    "    arxiv_fixed_n_samples_per_request = 100\n",
    "    n_cursor = n_samples // arxiv_fixed_n_samples_per_request\n",
    "\n",
    "    # Call the download function for arXiv\n",
    "    return download_preprints_with_publication_info(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        n_cursor=n_cursor,\n",
    "        output_format=output_format,\n",
    "        source=\"arxiv\",\n",
    "        category=economics_category_query,\n",
    "        published_in_journal=published_in_journal\n",
    "    )\n",
    "\n",
    "economics_categories = list(arxiv_taxonomy.get(\"Economics\", {}).keys())\n",
    "\n",
    "# Create extended list that includes related economics categories\n",
    "extended_econ_categories = economics_categories + [\n",
    "    \"q-fin.EC\",       # Economics in Quantitative Finance\n",
    "    \"q-fin.GN\",       # General Finance\n",
    "    \"q-fin.PM\",       # Portfolio Management\n",
    "    \"q-fin.RM\",       # Risk Management\n",
    "    \"q-fin.ST\",       # Statistical Finance\n",
    "    \"q-fin.TR\",       # Trading and Microstructure\n",
    "    \"economics\",      # Generic category\n",
    "    \"finance\",        # Generic category\n",
    "    \"econometrics\"    # Generic category\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7bb62",
   "metadata": {},
   "source": [
    "## Step 1: Fetching a Research Paper\n",
    "In this step, we download research papers from arxiv. Using the `download_economics_papers` function. Then we assess some research papers for whether they should be included in our research. Finally, we retrieve the paper from the database which was assessed to be of use to our research but which has not yet had a fake abstract generated for downstream use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a single economics paper into the database\n",
    "session = get_db_session()\n",
    "try:\n",
    "    download_economics_papers(start_date=\"2024-01-01\", end_date=\"2024-01-20\", n_samples=1, output_format=\"json\")\n",
    "    econ_papers_inclusion_assessment(n=1)\n",
    "    # Retrieve the inserted paper\n",
    "    paper = session.query(ResearchPaper).where(\n",
    "        ResearchPaper.inclusion_decision == True,\n",
    "        ResearchPaper.category.in_(extended_econ_categories),\n",
    "        # Doesn't have ResearchPaper.gpt4_incorrect_abstract\n",
    "        ResearchPaper.gpt4_incorrect_abstract.is_(None)\n",
    "    ).order_by(ResearchPaper.id.desc()).first()\n",
    "finally:\n",
    "    close_db_session(session)\n",
    "\n",
    "# Paper retrieved:\n",
    "print(f\"Paper ID: {paper.id}\")\n",
    "print(f\"Title: {paper.title}\")\n",
    "print(f\"Authors: {paper.authors}\")\n",
    "print(f\"Abstract: {paper.abstract}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34831e7",
   "metadata": {},
   "source": [
    "## Step 2: Generate a False Abstract\n",
    "We use the OpenAI API to generate a false abstract for the paper. The prompt is designed to elicit a response that mimics the style and content of a typical research abstract, but with fabricated information. This allows us to test the model's ability to generate coherent and contextually relevant text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modifier = AbstractModifier(prompt_template=economics_abstract_modification_prompt, domain=\"economics\", llm_client=BasicOpenAI())\n",
    "false_paper, event = modifier.modify_abstract(paper, save_event=True)\n",
    "print('Generated false abstract:', false_paper.gpt4_incorrect_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68004f",
   "metadata": {},
   "source": [
    "## Step 3: Computing Perplexity Scores\n",
    "Perplexity scores are calculated for both the original and false abstracts. These scores provide insights into the complexity and predictability of the text, which can be useful for evaluating the quality and coherence of the generated content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be084af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute perplexity scores\n",
    "client = TogetherClient()\n",
    "orig_text = paper.abstract\n",
    "false_text = false_paper.gpt4_incorrect_abstract if paper.inclusion_decision else None\n",
    "orig_perp = client.perplexity_score(orig_text) if orig_text else None\n",
    "false_perp = client.perplexity_score(false_text) if false_text else None\n",
    "print(f'Original Abstract Perplexity: {orig_perp:.2f}' if orig_perp is not None else 'No original abstract')\n",
    "print(f'False Abstract Perplexity: {false_perp:.2f}' if false_perp is not None else 'No false abstract')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
